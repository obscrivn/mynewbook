{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scikit-learn-text.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CtVIabzzb64m"
      },
      "cell_type": "markdown",
      "source": [
        "## Sklearan Practice\n",
        "Adapted from https://colab.research.google.com/github/RPI-DATA/course-intro-ml-app/blob/master/content/notebooks/16-intro-nlp/03-scikit-learn-text.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "tu1bzf2mbwrv"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2NPnavrXbwr9"
      },
      "cell_type": "markdown",
      "source": [
        "# Methods - Text Feature Extraction with Bag-of-Words Using Scikit Learn\n"
      ]
    },
    {
      "metadata": {
        "id": "8LgCSQvObwsK"
      },
      "cell_type": "code",
      "source": [
        "corpus = [\"Mr. Green killed Colonel Mustard in the study with the candlestick. \\\n",
        "Mr. Green is not a very nice fellow.\",\n",
        "     \"Professor Plum has a green plant in his study.\",\n",
        "    \"Miss Scarlett watered Professor Plum's green plant while he was away \\\n",
        "from his office last week.\"]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4smNnQ4lbwsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195002a6-1975-4bfd-855a-bf8dcb2dd158"
      },
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "tv6Puu2Rbwsh"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit(corpus)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqiZ3TMqbwtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fbee90-16cf-4362-e131-a288dd588125"
      },
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'away': 0,\n",
              " 'candlestick': 1,\n",
              " 'colonel': 2,\n",
              " 'fellow': 3,\n",
              " 'from': 4,\n",
              " 'green': 5,\n",
              " 'has': 6,\n",
              " 'he': 7,\n",
              " 'his': 8,\n",
              " 'in': 9,\n",
              " 'is': 10,\n",
              " 'killed': 11,\n",
              " 'last': 12,\n",
              " 'miss': 13,\n",
              " 'mr': 14,\n",
              " 'mustard': 15,\n",
              " 'nice': 16,\n",
              " 'not': 17,\n",
              " 'office': 18,\n",
              " 'plant': 19,\n",
              " 'plum': 20,\n",
              " 'professor': 21,\n",
              " 'scarlett': 22,\n",
              " 'study': 23,\n",
              " 'the': 24,\n",
              " 'very': 25,\n",
              " 'was': 26,\n",
              " 'watered': 27,\n",
              " 'week': 28,\n",
              " 'while': 29,\n",
              " 'with': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "TkLmhm0-bwte"
      },
      "cell_type": "code",
      "source": [
        "X_bag_of_words = vectorizer.transform(corpus)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PK18qqMabwtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b5783e-a4eb-4b45-9754-c28bf56ddf1e"
      },
      "cell_type": "code",
      "source": [
        "X_bag_of_words.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "huitq6-nbwtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14517474-dfd0-4d5e-8305-43364ce24047"
      },
      "cell_type": "code",
      "source": [
        "X_bag_of_words"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x31 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 39 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "bGbbbnT4bwtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426df986-6efa-4fd0-b673-b8cd2c64dd8e"
      },
      "cell_type": "code",
      "source": [
        "X_bag_of_words.toarray()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0,\n",
              "        0, 1, 2, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "9fMIWEOlbwty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3efdb7b-94e8-482f-91c4-f9cfa0d52674"
      },
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['away',\n",
              " 'candlestick',\n",
              " 'colonel',\n",
              " 'fellow',\n",
              " 'from',\n",
              " 'green',\n",
              " 'has',\n",
              " 'he',\n",
              " 'his',\n",
              " 'in',\n",
              " 'is',\n",
              " 'killed',\n",
              " 'last',\n",
              " 'miss',\n",
              " 'mr',\n",
              " 'mustard',\n",
              " 'nice',\n",
              " 'not',\n",
              " 'office',\n",
              " 'plant',\n",
              " 'plum',\n",
              " 'professor',\n",
              " 'scarlett',\n",
              " 'study',\n",
              " 'the',\n",
              " 'very',\n",
              " 'was',\n",
              " 'watered',\n",
              " 'week',\n",
              " 'while',\n",
              " 'with']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "iahQFIJ3bwt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac3af36-b012-43b4-aa78-2d6ba0c1672a"
      },
      "cell_type": "code",
      "source": [
        "vectorizer.inverse_transform(X_bag_of_words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['candlestick', 'colonel', 'fellow', 'green', 'in', 'is', 'killed',\n",
              "        'mr', 'mustard', 'nice', 'not', 'study', 'the', 'very', 'with'],\n",
              "       dtype='<U11'),\n",
              " array(['green', 'has', 'his', 'in', 'plant', 'plum', 'professor', 'study'],\n",
              "       dtype='<U11'),\n",
              " array(['away', 'from', 'green', 'he', 'his', 'last', 'miss', 'office',\n",
              "        'plant', 'plum', 'professor', 'scarlett', 'was', 'watered', 'week',\n",
              "        'while'], dtype='<U11')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "ZhcVPR0fbwt9"
      },
      "cell_type": "markdown",
      "source": [
        "# tf-idf Encoding\n",
        "\n",
        "\n",
        "The tf-idf encoding rescales words that are common to have less weight:"
      ]
    },
    {
      "metadata": {
        "id": "HEBFAHKHbwt9"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit(corpus)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbxcbXFvbwuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9acdd5-2f2a-4b84-e800-a8822f6ce715"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print(tfidf_vectorizer.transform(corpus).toarray())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.22 0.22 0.22 0.   0.26 0.   0.   0.   0.17 0.22 0.22 0.   0.\n",
            "  0.44 0.22 0.22 0.22 0.   0.   0.   0.   0.   0.17 0.44 0.22 0.   0.\n",
            "  0.   0.   0.22]\n",
            " [0.   0.   0.   0.   0.   0.27 0.46 0.   0.35 0.35 0.   0.   0.   0.\n",
            "  0.   0.   0.   0.   0.   0.35 0.35 0.35 0.   0.35 0.   0.   0.   0.\n",
            "  0.   0.   0.  ]\n",
            " [0.27 0.   0.   0.   0.27 0.16 0.   0.27 0.21 0.   0.   0.   0.27 0.27\n",
            "  0.   0.   0.   0.   0.27 0.21 0.21 0.21 0.27 0.   0.   0.   0.27 0.27\n",
            "  0.27 0.27 0.  ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Aa-zJuB6bwuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa90223e-8910-4f39-92cd-e43bd4135b75"
      },
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.get_feature_names()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['away',\n",
              " 'candlestick',\n",
              " 'colonel',\n",
              " 'fellow',\n",
              " 'from',\n",
              " 'green',\n",
              " 'has',\n",
              " 'he',\n",
              " 'his',\n",
              " 'in',\n",
              " 'is',\n",
              " 'killed',\n",
              " 'last',\n",
              " 'miss',\n",
              " 'mr',\n",
              " 'mustard',\n",
              " 'nice',\n",
              " 'not',\n",
              " 'office',\n",
              " 'plant',\n",
              " 'plum',\n",
              " 'professor',\n",
              " 'scarlett',\n",
              " 'study',\n",
              " 'the',\n",
              " 'very',\n",
              " 'was',\n",
              " 'watered',\n",
              " 'week',\n",
              " 'while',\n",
              " 'with']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "saj9osxVbwuI"
      },
      "cell_type": "markdown",
      "source": [
        "If you are interested in the mathematical details and equations, see this [external Notebook](http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/tfidf_scikit-learn.ipynb) that walks you through the computation."
      ]
    },
    {
      "metadata": {
        "id": "XRrBVZ8CbwuK"
      },
      "cell_type": "markdown",
      "source": [
        "# Bigrams and N-Grams\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BOMO-N4QbwuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf70dbe-3e8a-4180-e7d8-4b9cf54ffd59"
      },
      "cell_type": "code",
      "source": [
        "# look at sequences of tokens of minimum length 2 and maximum length 2\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "bigram_vectorizer.fit(corpus)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(ngram_range=(2, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "vDXcAcgzbwuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a4f650-d42d-45e8-f1ed-b82abc2109c5"
      },
      "cell_type": "code",
      "source": [
        "bigram_vectorizer.get_feature_names()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['away from',\n",
              " 'candlestick mr',\n",
              " 'colonel mustard',\n",
              " 'from his',\n",
              " 'green is',\n",
              " 'green killed',\n",
              " 'green plant',\n",
              " 'has green',\n",
              " 'he was',\n",
              " 'his office',\n",
              " 'his study',\n",
              " 'in his',\n",
              " 'in the',\n",
              " 'is not',\n",
              " 'killed colonel',\n",
              " 'last week',\n",
              " 'miss scarlett',\n",
              " 'mr green',\n",
              " 'mustard in',\n",
              " 'nice fellow',\n",
              " 'not very',\n",
              " 'office last',\n",
              " 'plant in',\n",
              " 'plant while',\n",
              " 'plum green',\n",
              " 'plum has',\n",
              " 'professor plum',\n",
              " 'scarlett watered',\n",
              " 'study with',\n",
              " 'the candlestick',\n",
              " 'the study',\n",
              " 'very nice',\n",
              " 'was away',\n",
              " 'watered professor',\n",
              " 'while he',\n",
              " 'with the']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "lt-yQvunbwuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad60b1e-dca2-4f40-f2df-5b029bf1d159"
      },
      "cell_type": "code",
      "source": [
        "bigram_vectorizer.transform(corpus).toarray()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "TNOdG_OebwuV"
      },
      "cell_type": "markdown",
      "source": [
        "Often we want to include unigrams (single tokens) AND bigrams, wich we can do by passing the following tuple as an argument to the `ngram_range` parameter of the `CountVectorizer` function:"
      ]
    },
    {
      "metadata": {
        "id": "OkBG4MThbwuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e37c835-d08c-48df-e4cb-6338783a961d"
      },
      "cell_type": "code",
      "source": [
        "gram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "gram_vectorizer.fit(corpus)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "L3HpFZV2bwvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ca805a-ceab-45e6-8c30-2ec745e0c06d"
      },
      "cell_type": "code",
      "source": [
        "gram_vectorizer.get_feature_names()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['away',\n",
              " 'away from',\n",
              " 'candlestick',\n",
              " 'candlestick mr',\n",
              " 'colonel',\n",
              " 'colonel mustard',\n",
              " 'fellow',\n",
              " 'from',\n",
              " 'from his',\n",
              " 'green',\n",
              " 'green is',\n",
              " 'green killed',\n",
              " 'green plant',\n",
              " 'has',\n",
              " 'has green',\n",
              " 'he',\n",
              " 'he was',\n",
              " 'his',\n",
              " 'his office',\n",
              " 'his study',\n",
              " 'in',\n",
              " 'in his',\n",
              " 'in the',\n",
              " 'is',\n",
              " 'is not',\n",
              " 'killed',\n",
              " 'killed colonel',\n",
              " 'last',\n",
              " 'last week',\n",
              " 'miss',\n",
              " 'miss scarlett',\n",
              " 'mr',\n",
              " 'mr green',\n",
              " 'mustard',\n",
              " 'mustard in',\n",
              " 'nice',\n",
              " 'nice fellow',\n",
              " 'not',\n",
              " 'not very',\n",
              " 'office',\n",
              " 'office last',\n",
              " 'plant',\n",
              " 'plant in',\n",
              " 'plant while',\n",
              " 'plum',\n",
              " 'plum green',\n",
              " 'plum has',\n",
              " 'professor',\n",
              " 'professor plum',\n",
              " 'scarlett',\n",
              " 'scarlett watered',\n",
              " 'study',\n",
              " 'study with',\n",
              " 'the',\n",
              " 'the candlestick',\n",
              " 'the study',\n",
              " 'very',\n",
              " 'very nice',\n",
              " 'was',\n",
              " 'was away',\n",
              " 'watered',\n",
              " 'watered professor',\n",
              " 'week',\n",
              " 'while',\n",
              " 'while he',\n",
              " 'with',\n",
              " 'with the']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "_HJRkBksbwvJ"
      },
      "cell_type": "code",
      "source": [
        "gram_vectorizer.transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NR2rkal8bwvL"
      },
      "cell_type": "markdown",
      "source": [
        "Character n-grams\n",
        "=================\n",
        "\n",
        "Sometimes it is also helpful not only to look at words, but to consider single characters instead.   \n",
        "That is particularly useful if we have very noisy data and want to identify the language, or if we want to predict something about a single word.\n",
        "We can simply look at characters instead of words by setting ``analyzer=\"char\"``.\n",
        "Looking at single characters is usually not very informative, but looking at longer n-grams of characters could be:"
      ]
    },
    {
      "metadata": {
        "id": "hYUVs99PbwvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5807ab1a-b5bc-40ee-c690-e5d8253b1287"
      },
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mr. Green killed Colonel Mustard in the study with the candlestick. Mr. Green is not a very nice fellow.',\n",
              " 'Professor Plum has a green plant in his study.',\n",
              " \"Miss Scarlett watered Professor Plum's green plant while he was away from his office last week.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "eyLIzQgibwvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676795ef-95c8-4d38-f29e-0a2ec1764def"
      },
      "cell_type": "code",
      "source": [
        "char_vectorizer = CountVectorizer(ngram_range=(2, 2), analyzer=\"char\")\n",
        "char_vectorizer.fit(corpus)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='char', ngram_range=(2, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "hJpM0J0MbwvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f8023f-1003-4daf-ff91-9aff52f80250"
      },
      "cell_type": "code",
      "source": [
        "print(char_vectorizer.get_feature_names())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' a', ' c', ' f', ' g', ' h', ' i', ' k', ' l', ' m', ' n', ' o', ' p', ' s', ' t', ' v', ' w', \"'s\", '. ', 'a ', 'an', 'ar', 'as', 'at', 'aw', 'ay', 'ca', 'ce', 'ck', 'co', 'd ', 'dl', 'dy', 'e ', 'ed', 'ee', 'ek', 'el', 'en', 'er', 'es', 'et', 'fe', 'ff', 'fi', 'fr', 'gr', 'h ', 'ha', 'he', 'hi', 'ic', 'il', 'in', 'is', 'it', 'k.', 'ki', 'l ', 'la', 'le', 'll', 'lo', 'lu', 'm ', \"m'\", 'mi', 'mr', 'mu', 'n ', 'nd', 'ne', 'ni', 'no', 'nt', 'of', 'ol', 'om', 'on', 'or', 'ot', 'ow', 'pl', 'pr', 'r ', 'r.', 'rd', 're', 'rl', 'ro', 'ry', 's ', 'sc', 'so', 'ss', 'st', 't ', 'ta', 'te', 'th', 'ti', 'tt', 'tu', 'ud', 'um', 'us', 've', 'w.', 'wa', 'we', 'wh', 'wi', 'y ', 'y.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4WRmIK0AbwvX"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnRnKkbobwvY"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}